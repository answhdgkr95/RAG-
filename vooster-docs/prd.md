# 제품 요구사항 문서(PRD)

## 1. 총괄 요약

RAG(Retrieval-Augmented Generation) 기반 문서 검색 시스템은 사용자가 PDF, 텍스트 등 다양한 작업 매뉴얼‧도면‧계약서를 업로드하고, 자연어 질문으로 정확한 근거와 함께 즉각적인 답변을 받을 수 있는 웹 서비스이다. ChatPDF 대비 산업 현장 맞춤형 기능(권한·OCR·태스크 Agent)을 제공하여 업무 효율과 정확성을 크게 향상시킨다.

## 2. 문제 정의

1. 현장 작업자는 방대한 매뉴얼 속 필요한 정보를 찾느라 시간을 소모한다.
2. 문서가 수시로 갱신되어 최신 버전 확인이 어렵다.
3. 잘못된 정보 전달로 안전·품질 사고 위험이 존재한다.
4. 기존 검색 솔루션은 키워드 위주라 맥락 이해가 부족하다.

## 3. 목표 및 목적

- 1차 목표: 업로드 문서에서 근거 기반 Q&A 제공
- 2차 목표: 권한·버전 관리 및 Agent 기반 고차 질문 지원
- 성공지표
  - Top-3 정답 포함률 ≥ 85%
  - 월간 활성 사용자(MAU) 5,000명
  - 평균 응답 속도 ≤ 3초
  - 잘못된 답변 신고율 ≤ 5%

## 4. 타깃 사용자

### 주사용자

- 건설·제조 현장 작업자, 엔지니어, 관리자
- 행동: 모바일/PC로 매뉴얼‧도면 열람, 즉시 Q&A 필요
- 니즈: 빠르고 정확한 문서 참조, 최신 버전 보장

### 부사용자

- HSE(안전)팀, 품질팀, 문서 관리자, 경영진

## 5. 사용자 스토리

- “현장 작업자로서, 부품 교체 매뉴얼을 찾지 않고도 ‘토크 값이 얼마야?’라고 질문해 즉시 답변과 근거를 얻고 싶다.”
- “문서 관리자로서, 문서 변경 시 변경 요약을 자동 생성하여 사용자에게 알리고 싶다.”
- “엔지니어로서, 도면 이미지를 올리고 ‘규격 위반사항 요약’ 같은 복합 질문을 처리하고 싶다.”

## 6. 기능 요구사항

### 핵심 기능

1. 문서 업로드
   - PDF, TXT, DOCX 지원, 최대 200MB
   - 업로드 시 확장자·바이러스 검사 100% 통과
2. 임베딩 & 벡터 DB 저장
   - 각 문단 최대 512 tokens 단위로 임베딩
   - DB: Milvus / Pinecone 선택, Top-k=5
   - 실패 시 재시도 3회, 로그 기록
3. 자연어 질문 & RAG 응답
   - OpenAI GPT-4o 또는 Llama2-70B-Chat
   - 근거 문장/문단 하이라이트 포함
   - 불확실성≥0.3일 때 “답변 불확실” 경고
4. 샘플 문서 탑재
   - 초기 2개 예제(설비 매뉴얼, 안전지침) 제공
5. 근거 문장 출력
   - UI에 collapse/expand 형태로 표시
   - 클릭 시 원본 문서 페이지로 이동

### 보조 기능 (Nice-to-Have)

1. 문서 분류
2. Agent 태스크(고차 질문)
3. 문서 요약(개요)
4. 도면/이미지 OCR
5. 권한 기반 접근(업로더 전용, Role: viewer/editor/admin)
6. 문서 변경 이력 및 변경점 요약
7. 시공 단계별 응답 분류
8. 일정 리마인더 생성
9. 오답 리포트 및 GPT 피드백

## 7. 비기능 요구사항

- 성능: 평균 응답 ≤3초, p95 ≤5초
- 보안: OAuth2.0, JWT, AES256 at rest, GDPR 준수
- 사용성: 모바일 반응형, WCAG 2.1 AA
- 확장성: 동시 접속 10,000명, 오토스케일링
- 호환성: Chrome, Edge, Safari 최신 2버전
- 가용성: 99.9% SLA

## 8. 기술 고려사항

- 아키텍처: React+Next.js(SSR) ‑> API Gateway ‑> Python FastAPI(Microservice) ‑> Vector DB + PostgreSQL
- 임베딩 모델: OpenAI text-embedding-3 / local Instructor-xl fallback
- Storage: AWS S3, 버전 관리 활성화
- 배포: Docker, Kubernetes, GitHub Actions CI/CD
- 모니터링: Prometheus, Grafana, Sentry
- 3rd-party: OCR(Tesseract/Google Vision API), Notification(Slack, Email)

## 9. 성공지표 & KPI

- MAU, 신규 가입률, 재방문률
- 질문당 평균 응답 시간  
  -Top-3 정확도, 오답 신고율
- 업로드 문서 수, 사용량(쿼리/일)
- 비용/쿼리 ≤ $0.002

## 10. 일정 & 마일스톤

- Phase 1 (M1~M2): 기본 업로드, 임베딩, Q&A, 샘플 문서
- Phase 2 (M3~M4): 권한 관리, 문서 분류, OCR, 요약
- Phase 3 (M5~M6): Agent 태스크, 변경 이력, 일정 리마인더, 오답 리포트
- Beta 출시: M4, 정식 GA: M6

## 11. 위험 및 대응

- 모델 정확도 부족 → 도메인 데이터 파인튜닝, 휴먼 리뷰
- 대용량 문서 처리 지연 → 배치 전처리, 캐싱
- 민감 정보 유출 → 데이터 마스킹, 권한 관리
- 사용자 채택 저조 → 현장 교육, 피드백 루프
- API 비용 급증 → 호출 최적화, 로컬 모델 하이브리드

## 12. 향후 고려

- 멀티언어 지원(영‧중)
- 온프레미스 패키지 제공
- 3D 도면·BIM 파일 분석
- AR 기기를 통한 현장 안내
- 지속 학습 파이프라인 구축
